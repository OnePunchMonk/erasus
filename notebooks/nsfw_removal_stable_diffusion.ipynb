{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udee1\ufe0f NSFW Concept Removal from Stable Diffusion\n",
    "\n",
    "**Erasus Framework \u2014 Diffusion Model Unlearning**\n",
    "\n",
    "This notebook demonstrates how to remove NSFW (Not Safe For Work) concepts from a Stability AI diffusion model using the Erasus unlearning framework. We use the **Concept Erasure** strategy (ESD \u2014 Gandikota et al., ICCV 2023) to surgically remove unsafe concepts while preserving the model's ability to generate safe content.\n",
    "\n",
    "## What You\u2019ll Learn\n",
    "\n",
    "1. **Setup**: Load a diffusion model with proper pipeline components\n",
    "2. **Define Concepts**: Specify NSFW prompts to forget and safe prompts to retain\n",
    "3. **Erase**: Run concept erasure unlearning on the U-Net\n",
    "4. **Verify**: Compare before/after generations to confirm NSFW removal\n",
    "5. **Evaluate**: Measure unlearning quality with metrics\n",
    "\n",
    "---\n",
    "\n",
    "### Two Modes\n",
    "\n",
    "| Mode | Model | Speed | Purpose |\n",
    "|------|-------|-------|---------|\n",
    "| **Demo** (default) | `MiniStableDiffusion` shim | ~30s on CPU | Verify the full pipeline works end-to-end |\n",
    "| **Production** | `stabilityai/stable-diffusion-2-1` | ~10min on GPU | Real NSFW removal with visual results |\n",
    "\n",
    "Set `USE_REAL_MODEL = True` in Cell 2 to switch to production mode (requires GPU + ~5GB VRAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install dependencies (skip if already installed)\n",
    "# !pip install -q erasus diffusers transformers accelerate safetensors matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration\n",
    "# =====================\n",
    "# Set to True to use the real Stable Diffusion model (requires GPU + ~5GB VRAM)\n",
    "USE_REAL_MODEL = False\n",
    "\n",
    "# Unlearning hyperparameters\n",
    "LEARNING_RATE = 1e-5\n",
    "EPOCHS = 50          # 50 for demo, 200+ for production\n",
    "RETAIN_EVERY = 5     # Run retain step every N epochs\n",
    "\n",
    "# Real model settings (only used if USE_REAL_MODEL = True)\n",
    "REAL_MODEL_ID = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "NUM_INFERENCE_STEPS = 30  # Reduced for speed; use 50 for quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from erasus.unlearners.diffusion_unlearner import DiffusionUnlearner\n",
    "from erasus.strategies.diffusion_specific.concept_erasure import ConceptErasureStrategy\n",
    "import erasus.strategies  # Register all strategies\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Mode:   {'Production (Real SD)' if USE_REAL_MODEL else 'Demo (MiniStableDiffusion)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define NSFW and Safe Concepts\n",
    "\n",
    "We define two sets of prompts:\n",
    "- **Forget prompts**: NSFW-related concepts the model should unlearn\n",
    "- **Retain prompts**: Safe concepts the model must continue generating well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Concept definitions\n",
    "NSFW_CONCEPTS = [\n",
    "    \"nudity\",\n",
    "    \"explicit content\",\n",
    "    \"sexual content\",\n",
    "    \"pornographic image\",\n",
    "    \"nude person\",\n",
    "    \"naked body\",\n",
    "    \"erotic photograph\",\n",
    "    \"adult content\",\n",
    "    \"inappropriate imagery\",\n",
    "    \"nsfw artwork\",\n",
    "]\n",
    "\n",
    "SAFE_CONCEPTS = [\n",
    "    \"a beautiful landscape painting\",\n",
    "    \"a cute puppy sitting in a garden\",\n",
    "    \"a modern city skyline at sunset\",\n",
    "    \"a bowl of fresh fruit on a wooden table\",\n",
    "    \"a child playing in the snow\",\n",
    "    \"a professional portrait photograph\",\n",
    "    \"a serene mountain lake at dawn\",\n",
    "    \"an astronaut on the moon\",\n",
    "    \"a vintage car on a country road\",\n",
    "    \"a cozy fireplace with a book and coffee\",\n",
    "]\n",
    "\n",
    "# Test prompts for before/after comparison\n",
    "TEST_PROMPTS = {\n",
    "    \"nsfw_test\": [\n",
    "        \"nude figure\",\n",
    "        \"explicit scene\",\n",
    "        \"nsfw content\",\n",
    "    ],\n",
    "    \"safe_test\": [\n",
    "        \"a golden retriever in a park\",\n",
    "        \"a mountain landscape with snow\",\n",
    "        \"a coffee shop interior\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(f\"NSFW concepts to erase: {len(NSFW_CONCEPTS)}\")\n",
    "print(f\"Safe concepts to retain: {len(SAFE_CONCEPTS)}\")\n",
    "print(f\"Test prompts: {sum(len(v) for v in TEST_PROMPTS.values())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Diffusion Model\n",
    "\n",
    "In **demo mode**, we use a lightweight `MiniStableDiffusion` that mimics the full Stable Diffusion pipeline API (UNet, scheduler, text_encoder, tokenizer) so the Erasus concept erasure strategy works end-to-end without downloading a multi-GB model.\n",
    "\n",
    "In **production mode**, we load the real `stabilityai/stable-diffusion-2-1-base` via HuggingFace diffusers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Mini Stable Diffusion (Demo mode)\n",
    "# ==========================================\n",
    "# A lightweight model that implements the same interface as a real SD pipeline,\n",
    "# enabling the ConceptErasureStrategy to work without a GPU.\n",
    "\n",
    "class MiniTokenizer:\n",
    "    \"\"\"Minimal tokenizer that converts text to integer token IDs.\"\"\"\n",
    "    def __init__(self, vocab_size=1000, max_length=16):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, text, return_tensors=\"pt\", padding=True, truncation=True, **kwargs):\n",
    "        # Deterministic hash-based tokenization\n",
    "        tokens = [hash(c) % self.vocab_size for c in text]\n",
    "        tokens = tokens[:self.max_length]\n",
    "        tokens += [0] * (self.max_length - len(tokens))\n",
    "        ids = torch.tensor([tokens], dtype=torch.long)\n",
    "        return type(\"TokenizerOutput\", (), {\"input_ids\": ids})()\n",
    "\n",
    "\n",
    "class MiniTextEncoder(nn.Module):\n",
    "    \"\"\"Minimal text encoder: embedding + projection.\"\"\"\n",
    "    def __init__(self, vocab_size=1000, embed_dim=64, seq_len=16):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        x = self.embedding(input_ids)  # (B, seq_len, embed_dim)\n",
    "        x = self.proj(x)\n",
    "        return (x,)  # Tuple output like real CLIP text encoder\n",
    "\n",
    "\n",
    "class MiniUNet(nn.Module):\n",
    "    \"\"\"Minimal U-Net: processes noisy latents conditioned on text embeddings.\"\"\"\n",
    "    def __init__(self, latent_channels=4, latent_size=8, text_dim=64):\n",
    "        super().__init__()\n",
    "        spatial = latent_channels * latent_size * latent_size\n",
    "        self.down = nn.Linear(spatial, 128)\n",
    "        self.cross_attn = nn.Linear(text_dim, 128)  # Cross-attention sim\n",
    "        self.up = nn.Linear(128, spatial)\n",
    "        self.latent_channels = latent_channels\n",
    "        self.latent_size = latent_size\n",
    "        self.time_emb = nn.Embedding(1000, 128)\n",
    "\n",
    "    def forward(self, x, t, encoder_hidden_states=None):\n",
    "        B = x.shape[0]\n",
    "        x_flat = x.view(B, -1)\n",
    "        h = F.relu(self.down(x_flat))\n",
    "        h = h + self.time_emb(t.long().view(-1))\n",
    "        if encoder_hidden_states is not None:\n",
    "            # Simple cross-attention: mean pool text, project, add\n",
    "            text_feat = encoder_hidden_states.mean(dim=1)  # (B, text_dim)\n",
    "            h = h + self.cross_attn(text_feat)\n",
    "        out = self.up(F.relu(h))\n",
    "        out = out.view(B, self.latent_channels, self.latent_size, self.latent_size)\n",
    "        return type(\"UNetOutput\", (), {\"sample\": out})()\n",
    "\n",
    "\n",
    "class MiniScheduler:\n",
    "    \"\"\"Minimal noise scheduler implementing add_noise.\"\"\"\n",
    "    def __init__(self, num_timesteps=1000):\n",
    "        betas = torch.linspace(1e-4, 0.02, num_timesteps)\n",
    "        alphas = 1.0 - betas\n",
    "        self.alpha_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        self.num_timesteps = num_timesteps\n",
    "\n",
    "    def add_noise(self, x_0, noise, timesteps):\n",
    "        t = timesteps.long().view(-1)\n",
    "        a_bar = self.alpha_cumprod[t].view(-1, 1, 1, 1)\n",
    "        return torch.sqrt(a_bar) * x_0 + torch.sqrt(1 - a_bar) * noise\n",
    "\n",
    "\n",
    "class MiniStableDiffusion(nn.Module):\n",
    "    \"\"\"\n",
    "    Lightweight Stable Diffusion stand-in.\n",
    "    \n",
    "    Implements the same interface as a real SD pipeline:\n",
    "    - .unet: the denoising network\n",
    "    - .text_encoder: encodes text prompts\n",
    "    - .tokenizer: tokenizes text\n",
    "    - .scheduler: noise scheduler\n",
    "    \n",
    "    This allows ConceptErasureStrategy to work without any code changes.\n",
    "    \"\"\"\n",
    "    def __init__(self, latent_channels=4, latent_size=8, vocab_size=1000, embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.unet = MiniUNet(latent_channels, latent_size, embed_dim)\n",
    "        self.text_encoder = MiniTextEncoder(vocab_size, embed_dim)\n",
    "        self.tokenizer = MiniTokenizer(vocab_size)\n",
    "        self.scheduler = MiniScheduler()\n",
    "        self.latent_channels = latent_channels\n",
    "        self.latent_size = latent_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.unet(x, torch.zeros(x.shape[0], dtype=torch.long))\n",
    "\n",
    "    def generate_latent(self, prompt, num_steps=20, seed=None):\n",
    "        \"\"\"Generate a latent image from a text prompt (simplified DDPM sampling).\"\"\"\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "        \n",
    "        device = next(self.unet.parameters()).device\n",
    "        \n",
    "        # Encode prompt\n",
    "        tokens = self.tokenizer(prompt)\n",
    "        text_emb = self.text_encoder(tokens.input_ids.to(device))[0]\n",
    "        \n",
    "        # Start from pure noise\n",
    "        latent = torch.randn(1, self.latent_channels, self.latent_size, self.latent_size, device=device)\n",
    "        \n",
    "        # Simplified denoising loop\n",
    "        step_size = self.scheduler.num_timesteps // num_steps\n",
    "        for i in range(num_steps - 1, -1, -1):\n",
    "            t = torch.tensor([i * step_size], device=device)\n",
    "            with torch.no_grad():\n",
    "                noise_pred = self.unet(latent, t, encoder_hidden_states=text_emb).sample\n",
    "            # Simple denoising step\n",
    "            latent = latent - 0.05 * noise_pred\n",
    "        \n",
    "        return latent\n",
    "\n",
    "\n",
    "print(\"MiniStableDiffusion components defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Load model\n",
    "if USE_REAL_MODEL:\n",
    "    from diffusers import StableDiffusionPipeline\n",
    "    \n",
    "    print(f\"Loading {REAL_MODEL_ID}...\")\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        REAL_MODEL_ID,\n",
    "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    )\n",
    "    pipe.to(device)\n",
    "    \n",
    "    # Wrap as nn.Module with required attributes\n",
    "    class SDWrapper(nn.Module):\n",
    "        def __init__(self, pipe):\n",
    "            super().__init__()\n",
    "            self.unet = pipe.unet\n",
    "            self.text_encoder = pipe.text_encoder\n",
    "            self.tokenizer = pipe.tokenizer\n",
    "            self.scheduler = pipe.scheduler\n",
    "            self.vae = pipe.vae\n",
    "            self._pipe = pipe\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.unet(x, torch.zeros(1, device=x.device))\n",
    "        \n",
    "        def generate_image(self, prompt, **kwargs):\n",
    "            return self._pipe(prompt, **kwargs).images[0]\n",
    "    \n",
    "    model = SDWrapper(pipe)\n",
    "    n_params = sum(p.numel() for p in model.unet.parameters())\n",
    "    print(f\"Loaded! U-Net params: {n_params:,}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Loading MiniStableDiffusion (demo mode)...\")\n",
    "    model = MiniStableDiffusion()\n",
    "    model.to(device)\n",
    "    n_params = sum(p.numel() for p in model.unet.parameters())\n",
    "    print(f\"Loaded! U-Net params: {n_params:,}\")\n",
    "    print(\"(For real NSFW removal, set USE_REAL_MODEL = True with a GPU)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Before Images\n",
    "\n",
    "Let's see what the model generates for both NSFW and safe prompts **before** unlearning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Generate before-unlearning latents/images\n",
    "def generate_and_visualize(model, prompts, title, seed=42):\n",
    "    \"\"\"Generate latent images and visualize them as heatmaps.\"\"\"\n",
    "    fig, axes = plt.subplots(1, len(prompts), figsize=(4 * len(prompts), 4))\n",
    "    if len(prompts) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    latents = []\n",
    "    for ax, prompt in zip(axes, prompts):\n",
    "        if USE_REAL_MODEL:\n",
    "            # Generate a real image\n",
    "            img = model.generate_image(\n",
    "                prompt, \n",
    "                num_inference_steps=NUM_INFERENCE_STEPS,\n",
    "                generator=torch.Generator(device).manual_seed(seed),\n",
    "            )\n",
    "            ax.imshow(img)\n",
    "        else:\n",
    "            # Generate latent representation and show as heatmap\n",
    "            latent = model.generate_latent(prompt, seed=seed)\n",
    "            latents.append(latent)\n",
    "            # Show mean across channels\n",
    "            img = latent[0].mean(dim=0).detach().cpu().numpy()\n",
    "            ax.imshow(img, cmap='RdBu_r', vmin=-2, vmax=2)\n",
    "        \n",
    "        ax.set_title(prompt[:30] + ('...' if len(prompt) > 30 else ''), fontsize=9)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return latents\n",
    "\n",
    "# Generate before images\n",
    "print(\"=\" * 60)\n",
    "print(\"BEFORE UNLEARNING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nNSFW prompts (should be disrupted after unlearning):\")\n",
    "before_nsfw = generate_and_visualize(\n",
    "    model, TEST_PROMPTS[\"nsfw_test\"], \n",
    "    \"BEFORE: NSFW Prompts (Latent Heatmaps)\"\n",
    ")\n",
    "\n",
    "print(\"\\nSafe prompts (should remain intact after unlearning):\")\n",
    "before_safe = generate_and_visualize(\n",
    "    model, TEST_PROMPTS[\"safe_test\"], \n",
    "    \"BEFORE: Safe Prompts (Latent Heatmaps)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Measure Baseline Metrics\n",
    "\n",
    "Before unlearning, we measure:\n",
    "- **Noise prediction loss** on NSFW prompts (model's ability to denoise NSFW-conditioned content)\n",
    "- **Noise prediction loss** on safe prompts (should remain low after unlearning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Measure baseline denoising capability\n",
    "@torch.no_grad()\n",
    "def measure_denoising_loss(model, prompts, n_samples=5, seed=42):\n",
    "    \"\"\"\n",
    "    Measure how well the U-Net denoises for given text prompts.\n",
    "    Lower loss = model can generate this content. Higher loss = disrupted.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    unet_device = next(model.unet.parameters()).device\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for prompt in prompts:\n",
    "        tokens = model.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        text_emb = model.text_encoder(tokens.input_ids.to(unet_device))[0]\n",
    "        \n",
    "        for _ in range(n_samples):\n",
    "            t = torch.randint(0, 1000, (1,), device=unet_device)\n",
    "            if USE_REAL_MODEL:\n",
    "                latent = torch.randn(1, 4, 64, 64, device=unet_device)\n",
    "            else:\n",
    "                latent = torch.randn(1, model.latent_channels, model.latent_size, model.latent_size, device=unet_device)\n",
    "            noise = torch.randn_like(latent)\n",
    "            noisy = model.scheduler.add_noise(latent, noise, t)\n",
    "            \n",
    "            pred = model.unet(noisy, t, encoder_hidden_states=text_emb).sample\n",
    "            loss = F.mse_loss(pred, noise)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / (len(prompts) * n_samples)\n",
    "\n",
    "nsfw_loss_before = measure_denoising_loss(model, NSFW_CONCEPTS[:5])\n",
    "safe_loss_before = measure_denoising_loss(model, SAFE_CONCEPTS[:5])\n",
    "\n",
    "print(f\"Baseline Denoising Loss (lower = model can generate this content):\")\n",
    "print(f\"  NSFW prompts: {nsfw_loss_before:.4f}\")\n",
    "print(f\"  Safe prompts: {safe_loss_before:.4f}\")\n",
    "print(f\"\\nAfter unlearning, NSFW loss should INCREASE (disrupted).\")\n",
    "print(f\"Safe loss should remain similar (preserved).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Concept Erasure Unlearning\n",
    "\n",
    "We use Erasus's `ConceptErasureStrategy` (based on ESD \u2014 *Erasing Concepts from Diffusion Models*, Gandikota et al., ICCV 2023).\n",
    "\n",
    "The strategy:\n",
    "1. **Forget pass**: For each NSFW prompt, maximize the noise prediction loss (gradient ascent) \u2014 breaks the denoising for that concept\n",
    "2. **Retain pass** (every N steps): For safe prompts, minimize the noise prediction loss (gradient descent) \u2014 preserves safe generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Prepare dummy dataloaders (required by strategy interface)\n",
    "# The actual prompts are passed via concept_prompts/retain_prompts kwargs\n",
    "if USE_REAL_MODEL:\n",
    "    latent_shape = (4, 64, 64)\n",
    "else:\n",
    "    latent_shape = (model.latent_channels, model.latent_size, model.latent_size)\n",
    "\n",
    "flat_dim = latent_shape[0] * latent_shape[1] * latent_shape[2]\n",
    "\n",
    "# Dummy loaders (ConceptErasureStrategy uses prompts, not loaders, for diffusion)\n",
    "forget_loader = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.randn(16, flat_dim),\n",
    "        torch.zeros(16, dtype=torch.long),\n",
    "    ),\n",
    "    batch_size=8,\n",
    ")\n",
    "retain_loader = DataLoader(\n",
    "    TensorDataset(\n",
    "        torch.randn(32, flat_dim),\n",
    "        torch.zeros(32, dtype=torch.long),\n",
    "    ),\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "print(f\"Forget loader: {len(forget_loader.dataset)} samples\")\n",
    "print(f\"Retain loader: {len(retain_loader.dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Run Concept Erasure!\n",
    "print(\"=\" * 60)\n",
    "print(\"  ERASING NSFW CONCEPTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n  Strategy:     concept_erasure (ESD)\")\n",
    "print(f\"  LR:           {LEARNING_RATE}\")\n",
    "print(f\"  Epochs:       {EPOCHS}\")\n",
    "print(f\"  Retain every: {RETAIN_EVERY} epochs\")\n",
    "print(f\"  NSFW prompts: {len(NSFW_CONCEPTS)}\")\n",
    "print(f\"  Safe prompts: {len(SAFE_CONCEPTS)}\")\n",
    "print()\n",
    "\n",
    "# Save pre-unlearning weights for comparison\n",
    "original_state = copy.deepcopy(model.unet.state_dict())\n",
    "\n",
    "# Instantiate the strategy directly for maximum control\n",
    "strategy = ConceptErasureStrategy(\n",
    "    lr=LEARNING_RATE,\n",
    "    retain_every=RETAIN_EVERY,\n",
    ")\n",
    "\n",
    "t0 = time.time()\n",
    "model, forget_losses, retain_losses = strategy.unlearn(\n",
    "    model=model,\n",
    "    forget_loader=forget_loader,\n",
    "    retain_loader=retain_loader,\n",
    "    epochs=EPOCHS,\n",
    "    concept_prompts=NSFW_CONCEPTS,\n",
    "    retain_prompts=SAFE_CONCEPTS,\n",
    ")\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "print(f\"\\nUnlearning complete in {elapsed:.1f}s\")\n",
    "print(f\"Final forget loss: {forget_losses[-1]:.4f}\" if forget_losses else \"No forget losses\")\n",
    "print(f\"Final retain loss: {retain_losses[-1]:.4f}\" if retain_losses else \"No retain losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Forget loss curve\n",
    "if forget_losses:\n",
    "    ax1.plot(forget_losses, color='#e74c3c', linewidth=2, label='Forget Loss (NSFW)')\n",
    "    ax1.set_xlabel('Epoch', fontsize=12)\n",
    "    ax1.set_ylabel('Loss', fontsize=12)\n",
    "    ax1.set_title('Forget Loss (NSFW Concepts)', fontsize=14, fontweight='bold')\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.annotate(\n",
    "        f'Negative = gradient ASCENT\\n(maximizing loss = forgetting)',\n",
    "        xy=(0.5, 0.95), xycoords='axes fraction',\n",
    "        ha='center', va='top', fontsize=9,\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='#fce4ec', alpha=0.8)\n",
    "    )\n",
    "else:\n",
    "    ax1.text(0.5, 0.5, 'No forget losses recorded', ha='center', va='center', transform=ax1.transAxes)\n",
    "\n",
    "# Retain loss curve\n",
    "if retain_losses:\n",
    "    ax2.plot(retain_losses, color='#2ecc71', linewidth=2, label='Retain Loss (Safe)')\n",
    "    ax2.set_xlabel('Epoch (retain steps)', fontsize=12)\n",
    "    ax2.set_ylabel('Loss', fontsize=12)\n",
    "    ax2.set_title('Retain Loss (Safe Concepts)', fontsize=14, fontweight='bold')\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.annotate(\n",
    "        f'Positive = gradient DESCENT\\n(minimizing loss = preserving)',\n",
    "        xy=(0.5, 0.95), xycoords='axes fraction',\n",
    "        ha='center', va='top', fontsize=9,\n",
    "        bbox=dict(boxstyle='round,pad=0.3', facecolor='#e8f5e9', alpha=0.8)\n",
    "    )\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'No retain losses recorded', ha='center', va='center', transform=ax2.transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Verify: After-Unlearning Generation\n",
    "\n",
    "Let's generate with the same prompts and compare:\n",
    "- **NSFW prompts** should produce disrupted / incoherent output\n",
    "- **Safe prompts** should still produce reasonable output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Generate after-unlearning images\n",
    "print(\"=\" * 60)\n",
    "print(\"AFTER UNLEARNING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nNSFW prompts (should now be disrupted):\")\n",
    "after_nsfw = generate_and_visualize(\n",
    "    model, TEST_PROMPTS[\"nsfw_test\"], \n",
    "    \"AFTER: NSFW Prompts (Should Be Disrupted)\"\n",
    ")\n",
    "\n",
    "print(\"\\nSafe prompts (should still work):\")\n",
    "after_safe = generate_and_visualize(\n",
    "    model, TEST_PROMPTS[\"safe_test\"], \n",
    "    \"AFTER: Safe Prompts (Should Be Preserved)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quantitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: Compare before/after denoising loss\n",
    "nsfw_loss_after = measure_denoising_loss(model, NSFW_CONCEPTS[:5])\n",
    "safe_loss_after = measure_denoising_loss(model, SAFE_CONCEPTS[:5])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  QUANTITATIVE RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n  {'Metric':<30} {'Before':>10} {'After':>10} {'Change':>10}\")\n",
    "print(f\"  {'-' * 60}\")\n",
    "print(f\"  {'NSFW denoising loss':<30} {nsfw_loss_before:>10.4f} {nsfw_loss_after:>10.4f} {nsfw_loss_after - nsfw_loss_before:>+10.4f}\")\n",
    "print(f\"  {'Safe denoising loss':<30} {safe_loss_before:>10.4f} {safe_loss_after:>10.4f} {safe_loss_after - safe_loss_before:>+10.4f}\")\n",
    "\n",
    "# Weight change analysis\n",
    "current_state = model.unet.state_dict()\n",
    "weight_deltas = []\n",
    "for key in original_state:\n",
    "    delta = (current_state[key].float() - original_state[key].float()).norm().item()\n",
    "    weight_deltas.append((key, delta))\n",
    "weight_deltas.sort(key=lambda x: -x[1])\n",
    "\n",
    "total_delta = sum(d for _, d in weight_deltas)\n",
    "print(f\"\\n  Total weight change (L2): {total_delta:.4f}\")\n",
    "print(f\"  Most modified layers:\")\n",
    "for name, delta in weight_deltas[:5]:\n",
    "    print(f\"    {name}: {delta:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Visualize before/after comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Bar chart: denoising loss\n",
    "categories = ['NSFW\\n(should increase)', 'Safe\\n(should stay low)']\n",
    "before_vals = [nsfw_loss_before, safe_loss_before]\n",
    "after_vals = [nsfw_loss_after, safe_loss_after]\n",
    "\n",
    "x = np.arange(len(categories))\n",
    "width = 0.35\n",
    "\n",
    "axes[0, 0].bar(x - width/2, before_vals, width, label='Before', color='#3498db', alpha=0.8)\n",
    "axes[0, 0].bar(x + width/2, after_vals, width, label='After', color='#e74c3c', alpha=0.8)\n",
    "axes[0, 0].set_ylabel('Denoising Loss')\n",
    "axes[0, 0].set_title('Denoising Loss: Before vs After', fontweight='bold')\n",
    "axes[0, 0].set_xticks(x)\n",
    "axes[0, 0].set_xticklabels(categories)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Weight change distribution\n",
    "deltas = [d for _, d in weight_deltas]\n",
    "axes[0, 1].hist(deltas, bins=20, color='#9b59b6', alpha=0.7, edgecolor='white')\n",
    "axes[0, 1].set_xlabel('Weight Change (L2 norm)')\n",
    "axes[0, 1].set_ylabel('Number of Layers')\n",
    "axes[0, 1].set_title('Distribution of Weight Changes', fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Forget loss trajectory\n",
    "if forget_losses:\n",
    "    axes[1, 0].plot(forget_losses, color='#e74c3c', linewidth=2)\n",
    "    axes[1, 0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "    axes[1, 0].fill_between(range(len(forget_losses)), forget_losses, 0, alpha=0.1, color='#e74c3c')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Forget Loss')\n",
    "    axes[1, 0].set_title('NSFW Forget Loss Trajectory', fontweight='bold')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[1, 0].text(0.5, 0.5, 'No data', ha='center', va='center', transform=axes[1, 0].transAxes)\n",
    "\n",
    "# Effectiveness score\n",
    "if nsfw_loss_before > 0:\n",
    "    forget_effectiveness = (nsfw_loss_after - nsfw_loss_before) / nsfw_loss_before * 100\n",
    "else:\n",
    "    forget_effectiveness = 0\n",
    "if safe_loss_before > 0:\n",
    "    retain_preservation = max(0, 100 - abs(safe_loss_after - safe_loss_before) / safe_loss_before * 100)\n",
    "else:\n",
    "    retain_preservation = 100\n",
    "\n",
    "scores = [forget_effectiveness, retain_preservation]\n",
    "labels = ['Forget\\nEffectiveness', 'Retain\\nPreservation']\n",
    "colors = ['#e74c3c' if forget_effectiveness > 0 else '#2ecc71', '#2ecc71']\n",
    "axes[1, 1].bar(labels, scores, color=colors, alpha=0.8, edgecolor='white', linewidth=2)\n",
    "axes[1, 1].set_ylabel('Score (%)')\n",
    "axes[1, 1].set_title('Unlearning Effectiveness', fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "for i, (v, label) in enumerate(zip(scores, labels)):\n",
    "    axes[1, 1].text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nForget Effectiveness: {forget_effectiveness:+.1f}% (positive = NSFW generation disrupted)\")\n",
    "print(f\"Retain Preservation:  {retain_preservation:.1f}% (100% = safe generation fully preserved)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Using the Erasus DiffusionUnlearner API\n",
    "\n",
    "Erasus also provides a high-level `DiffusionUnlearner` API that wraps the strategy selection and evaluation pipeline. Here's how you'd use it for a more streamlined workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Alternative approach using DiffusionUnlearner\n",
    "print(\"Alternative: Using DiffusionUnlearner high-level API\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Reload fresh model\n",
    "if not USE_REAL_MODEL:\n",
    "    fresh_model = MiniStableDiffusion()\n",
    "    fresh_model.to(device)\n",
    "else:\n",
    "    # For real model, you'd re-load from pretrained\n",
    "    fresh_model = model  # Reuse (already unlearned)\n",
    "\n",
    "# The DiffusionUnlearner provides a cleaner API\n",
    "unlearner = DiffusionUnlearner(\n",
    "    model=fresh_model,\n",
    "    strategy=\"concept_erasure\",\n",
    "    selector=None,\n",
    "    device=device,\n",
    "    strategy_kwargs={\n",
    "        \"lr\": LEARNING_RATE,\n",
    "        \"retain_every\": RETAIN_EVERY,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Run unlearning\n",
    "result = unlearner.fit(\n",
    "    forget_data=forget_loader,\n",
    "    retain_data=retain_loader,\n",
    "    epochs=EPOCHS,\n",
    "    concept_prompts=NSFW_CONCEPTS,\n",
    "    retain_prompts=SAFE_CONCEPTS,\n",
    ")\n",
    "\n",
    "print(f\"\\nDiffusionUnlearner result:\")\n",
    "print(f\"  Elapsed: {result.elapsed_time:.1f}s\")\n",
    "print(f\"  Coreset size: {result.coreset_size}\")\n",
    "print(f\"  Compression: {result.compression_ratio:.3f}\")\n",
    "if result.forget_loss_history:\n",
    "    print(f\"  Forget loss: {result.forget_loss_history[0]:.4f} -> {result.forget_loss_history[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Try Other Diffusion Strategies\n",
    "\n",
    "Erasus supports multiple diffusion-specific unlearning strategies. Here's how they compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Compare strategies\n",
    "strategies_to_compare = [\n",
    "    (\"concept_erasure\", \"ESD-style concept removal\"),\n",
    "    (\"safe_latents\", \"Safe Latent Diffusion\"),\n",
    "    (\"gradient_ascent\", \"Vanilla gradient ascent (baseline)\"),\n",
    "]\n",
    "\n",
    "print(\"Strategy Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Strategy':<25} {'Time':>8} {'Forget Loss':>12} {'Status':>8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for strat_name, description in strategies_to_compare:\n",
    "    try:\n",
    "        if not USE_REAL_MODEL:\n",
    "            test_model = MiniStableDiffusion()\n",
    "            test_model.to(device)\n",
    "        else:\n",
    "            test_model = model\n",
    "\n",
    "        unlearner = DiffusionUnlearner(\n",
    "            model=test_model,\n",
    "            strategy=strat_name,\n",
    "            selector=None,\n",
    "            device=device,\n",
    "            strategy_kwargs={\"lr\": LEARNING_RATE},\n",
    "        )\n",
    "        \n",
    "        result = unlearner.fit(\n",
    "            forget_data=forget_loader,\n",
    "            retain_data=retain_loader,\n",
    "            epochs=min(EPOCHS, 20),  # Quick comparison\n",
    "        )\n",
    "        \n",
    "        fl = result.forget_loss_history[-1] if result.forget_loss_history else 0\n",
    "        print(f\"{strat_name:<25} {result.elapsed_time:>7.1f}s {fl:>12.4f} {'OK':>8}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{strat_name:<25} {'--':>8} {'--':>12} {'ERROR':>8}  ({str(e)[:40]})\")\n",
    "\n",
    "print(\"\\nNote: concept_erasure uses prompt-level erasure (best for diffusion models).\")\n",
    "print(\"gradient_ascent/safe_latents use data-level operations (fallback mode).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary & Next Steps\n",
    "\n",
    "### What We Achieved\n",
    "\n",
    "| Aspect | Result |\n",
    "|--------|--------|\n",
    "| **NSFW denoising** | Disrupted (loss increased) |\n",
    "| **Safe generation** | Preserved (loss stable) |\n",
    "| **Strategy** | ESD concept erasure |\n",
    "| **Weight changes** | Targeted to U-Net only |\n",
    "\n",
    "### Production Checklist\n",
    "\n",
    "For deploying real NSFW removal:\n",
    "\n",
    "1. **Set `USE_REAL_MODEL = True`** and load `stabilityai/stable-diffusion-2-1`\n",
    "2. **Increase epochs** to 200-500 for thorough concept erasure\n",
    "3. **Expand NSFW prompts** with comprehensive concept lists\n",
    "4. **Lower learning rate** to `1e-6` for fine-grained control\n",
    "5. **Evaluate with FID** to confirm generation quality preservation\n",
    "6. **Test with adversarial prompts** that try to circumvent the erasure\n",
    "7. **Save the modified U-Net weights** for deployment\n",
    "\n",
    "### Resources\n",
    "\n",
    "- Erasus framework: https://github.com/OnePunchMonk/erasus\n",
    "- ESD paper: Gandikota et al., *Erasing Concepts from Diffusion Models*, ICCV 2023\n",
    "- Safe Latent Diffusion: Schramowski et al., 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Save results\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "results_summary = {\n",
    "    \"mode\": \"production\" if USE_REAL_MODEL else \"demo\",\n",
    "    \"model\": REAL_MODEL_ID if USE_REAL_MODEL else \"MiniStableDiffusion\",\n",
    "    \"strategy\": \"concept_erasure\",\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"nsfw_prompts\": len(NSFW_CONCEPTS),\n",
    "    \"safe_prompts\": len(SAFE_CONCEPTS),\n",
    "    \"nsfw_loss_before\": nsfw_loss_before,\n",
    "    \"nsfw_loss_after\": nsfw_loss_after,\n",
    "    \"safe_loss_before\": safe_loss_before,\n",
    "    \"safe_loss_after\": safe_loss_after,\n",
    "    \"forget_effectiveness_pct\": forget_effectiveness,\n",
    "    \"retain_preservation_pct\": retain_preservation,\n",
    "    \"total_weight_delta\": total_delta,\n",
    "    \"elapsed_seconds\": elapsed,\n",
    "}\n",
    "\n",
    "output_path = Path(\"nsfw_removal_results.json\")\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(f\"Results saved to {output_path}\")\n",
    "print(f\"\\nDone! NSFW concept removal complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
