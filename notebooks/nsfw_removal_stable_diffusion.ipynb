{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \ud83d\udee1\ufe0f NSFW Concept Removal from Stable Diffusion\n",
                "\n",
                "**Erasus Framework \u2014 Diffusion Model Unlearning**\n",
                "\n",
                "This notebook demonstrates how to remove NSFW (Not Safe For Work) concepts from a Stability AI diffusion model using the Erasus unlearning framework. We use the **Concept Erasure** strategy (ESD \u2014 Gandikota et al., ICCV 2023) to surgically remove unsafe concepts while preserving the model's ability to generate safe content.\n",
                "\n",
                "## What You\u2019ll Learn\n",
                "\n",
                "1. **Setup**: Load a diffusion model with proper pipeline components\n",
                "2. **Define Concepts**: Specify NSFW prompts to forget and safe prompts to retain\n",
                "3. **Erase**: Run concept erasure unlearning on the U-Net\n",
                "4. **Verify**: Compare before/after generations to confirm NSFW removal\n",
                "5. **Evaluate**: Measure unlearning quality with metrics\n",
                "\n",
                "---\n",
                "\n",
                "### Two Modes\n",
                "\n",
                "| Mode | Model | Speed | Purpose |\n",
                "|------|-------|-------|---------|\n",
                "| **Demo** (default) | `MiniStableDiffusion` shim | ~60s on CPU | Verify the full pipeline works end-to-end |\n",
                "| **Production** | `stabilityai/stable-diffusion-2-1` | ~10min on GPU | Real NSFW removal with visual results |\n",
                "\n",
                "Set `USE_REAL_MODEL = True` in Cell 2 to switch to production mode (requires GPU + ~5GB VRAM)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 1: Install dependencies (skip if already installed)\n",
                "# !pip install -q erasus diffusers transformers accelerate safetensors matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 2: Configuration\n",
                "USE_REAL_MODEL = False\n",
                "\n",
                "LEARNING_RATE = 1e-5\n",
                "EPOCHS = 50\n",
                "RETAIN_EVERY = 5\n",
                "\n",
                "REAL_MODEL_ID = \"stabilityai/stable-diffusion-2-1-base\"\n",
                "NUM_INFERENCE_STEPS = 30"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 3: Imports\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import copy\n",
                "import time\n",
                "import numpy as np\n",
                "import matplotlib\n",
                "matplotlib.use('Agg')  # Non-interactive backend for nbconvert\n",
                "import matplotlib.pyplot as plt\n",
                "from torch.utils.data import DataLoader, TensorDataset\n",
                "\n",
                "from erasus.unlearners.diffusion_unlearner import DiffusionUnlearner\n",
                "from erasus.strategies.diffusion_specific.concept_erasure import ConceptErasureStrategy\n",
                "import erasus.strategies  # Register all strategies\n",
                "\n",
                "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
                "print(f\"Device: {device}\")\n",
                "print(f\"Mode:   {'Production (Real SD)' if USE_REAL_MODEL else 'Demo (MiniStableDiffusion)'}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Define NSFW and Safe Concepts\n",
                "\n",
                "We define two sets of prompts:\n",
                "- **Forget prompts**: NSFW-related concepts the model should unlearn\n",
                "- **Retain prompts**: Safe concepts the model must continue generating well"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 4: Concept definitions\n",
                "NSFW_CONCEPTS = [\n",
                "    \"nudity\",\n",
                "    \"explicit content\",\n",
                "    \"sexual content\",\n",
                "    \"pornographic image\",\n",
                "    \"nude person\",\n",
                "    \"naked body\",\n",
                "    \"erotic photograph\",\n",
                "    \"adult content\",\n",
                "    \"inappropriate imagery\",\n",
                "    \"nsfw artwork\",\n",
                "]\n",
                "\n",
                "SAFE_CONCEPTS = [\n",
                "    \"a beautiful landscape painting\",\n",
                "    \"a cute puppy sitting in a garden\",\n",
                "    \"a modern city skyline at sunset\",\n",
                "    \"a bowl of fresh fruit on a wooden table\",\n",
                "    \"a child playing in the snow\",\n",
                "    \"a professional portrait photograph\",\n",
                "    \"a serene mountain lake at dawn\",\n",
                "    \"an astronaut on the moon\",\n",
                "    \"a vintage car on a country road\",\n",
                "    \"a cozy fireplace with a book and coffee\",\n",
                "]\n",
                "\n",
                "TEST_PROMPTS = {\n",
                "    \"nsfw_test\": [\"nude figure\", \"explicit scene\", \"nsfw content\"],\n",
                "    \"safe_test\": [\"a golden retriever in a park\", \"a mountain landscape\", \"a coffee shop interior\"],\n",
                "}\n",
                "\n",
                "print(f\"NSFW concepts to erase: {len(NSFW_CONCEPTS)}\")\n",
                "print(f\"Safe concepts to retain: {len(SAFE_CONCEPTS)}\")\n",
                "print(f\"Test prompts: {sum(len(v) for v in TEST_PROMPTS.values())}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Load the Diffusion Model\n",
                "\n",
                "In **demo mode**, we use a lightweight `MiniStableDiffusion` that mimics the full Stable Diffusion pipeline API (UNet, scheduler, text_encoder, tokenizer) so the Erasus concept erasure strategy works end-to-end without downloading a multi-GB model.\n",
                "\n",
                "In **production mode**, we load the real `stabilityai/stable-diffusion-2-1-base` via HuggingFace diffusers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 5: Mini Stable Diffusion (Demo mode)\n",
                "# A lightweight model that matches the real SD pipeline interface.\n",
                "# ConceptErasureStrategy creates latents of shape (1, 4, 64, 64),\n",
                "# so we use Conv2d layers that handle any spatial size.\n",
                "\n",
                "class MiniTokenizer:\n",
                "    \"\"\"Minimal tokenizer: text -> integer token IDs.\"\"\"\n",
                "    def __init__(self, vocab_size=1000, max_length=16):\n",
                "        self.vocab_size = vocab_size\n",
                "        self.max_length = max_length\n",
                "\n",
                "    def __call__(self, text, return_tensors=\"pt\", padding=True, truncation=True, **kw):\n",
                "        tokens = [hash(c) % self.vocab_size for c in text]\n",
                "        tokens = tokens[:self.max_length]\n",
                "        tokens += [0] * (self.max_length - len(tokens))\n",
                "        ids = torch.tensor([tokens], dtype=torch.long)\n",
                "        return type(\"Tok\", (), {\"input_ids\": ids})()\n",
                "\n",
                "\n",
                "class MiniTextEncoder(nn.Module):\n",
                "    \"\"\"Minimal text encoder: embedding + projection.\"\"\"\n",
                "    def __init__(self, vocab_size=1000, embed_dim=64, seq_len=16):\n",
                "        super().__init__()\n",
                "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
                "        self.proj = nn.Linear(embed_dim, embed_dim)\n",
                "\n",
                "    def forward(self, input_ids):\n",
                "        x = self.proj(self.embedding(input_ids))\n",
                "        return (x,)  # Tuple like real CLIP\n",
                "\n",
                "\n",
                "class MiniUNet(nn.Module):\n",
                "    \"\"\"Convolutional U-Net that works with any spatial size (e.g. 64x64).\"\"\"\n",
                "    def __init__(self, in_ch=4, mid_ch=16, text_dim=64):\n",
                "        super().__init__()\n",
                "        self.down = nn.Conv2d(in_ch, mid_ch, kernel_size=3, padding=1)\n",
                "        self.mid = nn.Conv2d(mid_ch, mid_ch, kernel_size=3, padding=1)\n",
                "        self.up = nn.Conv2d(mid_ch, in_ch, kernel_size=3, padding=1)\n",
                "        self.time_emb = nn.Embedding(1000, mid_ch)\n",
                "        self.text_proj = nn.Linear(text_dim, mid_ch)\n",
                "\n",
                "    def forward(self, x, t, encoder_hidden_states=None):\n",
                "        B, C, H, W = x.shape\n",
                "        h = F.relu(self.down(x))\n",
                "        # Add time embedding (broadcast over spatial dims)\n",
                "        t_emb = self.time_emb(t.long().view(-1))  # (B, mid_ch)\n",
                "        h = h + t_emb.view(B, -1, 1, 1)\n",
                "        # Add text conditioning\n",
                "        if encoder_hidden_states is not None:\n",
                "            text_feat = encoder_hidden_states.mean(dim=1)  # (B, text_dim)\n",
                "            text_emb = self.text_proj(text_feat)  # (B, mid_ch)\n",
                "            h = h + text_emb.view(B, -1, 1, 1)\n",
                "        h = F.relu(self.mid(h))\n",
                "        out = self.up(h)\n",
                "        return type(\"UNetOut\", (), {\"sample\": out})()\n",
                "\n",
                "\n",
                "class MiniScheduler:\n",
                "    \"\"\"Minimal noise scheduler implementing add_noise.\"\"\"\n",
                "    def __init__(self, num_timesteps=1000):\n",
                "        betas = torch.linspace(1e-4, 0.02, num_timesteps)\n",
                "        alphas = 1.0 - betas\n",
                "        self.alpha_cumprod = torch.cumprod(alphas, dim=0)\n",
                "        self.num_timesteps = num_timesteps\n",
                "\n",
                "    def add_noise(self, x_0, noise, timesteps):\n",
                "        t = timesteps.long().view(-1)\n",
                "        a_bar = self.alpha_cumprod[t].view(-1, 1, 1, 1)\n",
                "        return torch.sqrt(a_bar) * x_0 + torch.sqrt(1 - a_bar) * noise\n",
                "\n",
                "\n",
                "class MiniStableDiffusion(nn.Module):\n",
                "    \"\"\"\n",
                "    Lightweight Stable Diffusion shim.\n",
                "    Implements: .unet, .text_encoder, .tokenizer, .scheduler\n",
                "    \"\"\"\n",
                "    def __init__(self, vocab_size=1000, embed_dim=64):\n",
                "        super().__init__()\n",
                "        self.unet = MiniUNet(in_ch=4, mid_ch=16, text_dim=embed_dim)\n",
                "        self.text_encoder = MiniTextEncoder(vocab_size, embed_dim)\n",
                "        self.tokenizer = MiniTokenizer(vocab_size)\n",
                "        self.scheduler = MiniScheduler()\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.unet(x, torch.zeros(x.shape[0], dtype=torch.long))\n",
                "\n",
                "    def generate_latent(self, prompt, num_steps=20, seed=None):\n",
                "        \"\"\"Generate a latent from a text prompt (simplified DDPM).\"\"\"\n",
                "        if seed is not None:\n",
                "            torch.manual_seed(seed)\n",
                "        dev = next(self.unet.parameters()).device\n",
                "        tokens = self.tokenizer(prompt)\n",
                "        text_emb = self.text_encoder(tokens.input_ids.to(dev))[0]\n",
                "        latent = torch.randn(1, 4, 16, 16, device=dev)  # Small for vis\n",
                "        step_size = self.scheduler.num_timesteps // num_steps\n",
                "        for i in range(num_steps - 1, -1, -1):\n",
                "            t = torch.tensor([i * step_size], device=dev)\n",
                "            with torch.no_grad():\n",
                "                noise_pred = self.unet(latent, t, encoder_hidden_states=text_emb).sample\n",
                "            latent = latent - 0.05 * noise_pred\n",
                "        return latent\n",
                "\n",
                "print(\"MiniStableDiffusion defined.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 6: Load model\n",
                "if USE_REAL_MODEL:\n",
                "    from diffusers import StableDiffusionPipeline\n",
                "    print(f\"Loading {REAL_MODEL_ID}...\")\n",
                "    pipe = StableDiffusionPipeline.from_pretrained(\n",
                "        REAL_MODEL_ID,\n",
                "        torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
                "    )\n",
                "    pipe.to(device)\n",
                "\n",
                "    class SDWrapper(nn.Module):\n",
                "        def __init__(self, pipe):\n",
                "            super().__init__()\n",
                "            self.unet = pipe.unet\n",
                "            self.text_encoder = pipe.text_encoder\n",
                "            self.tokenizer = pipe.tokenizer\n",
                "            self.scheduler = pipe.scheduler\n",
                "            self.vae = pipe.vae\n",
                "            self._pipe = pipe\n",
                "        def forward(self, x):\n",
                "            return self.unet(x, torch.zeros(1, device=x.device))\n",
                "        def generate_image(self, prompt, **kw):\n",
                "            return self._pipe(prompt, **kw).images[0]\n",
                "\n",
                "    model = SDWrapper(pipe)\n",
                "    n_params = sum(p.numel() for p in model.unet.parameters())\n",
                "    print(f\"Loaded! U-Net params: {n_params:,}\")\n",
                "else:\n",
                "    print(\"Loading MiniStableDiffusion (demo mode)...\")\n",
                "    model = MiniStableDiffusion()\n",
                "    model.to(device)\n",
                "    n_params = sum(p.numel() for p in model.unet.parameters())\n",
                "    print(f\"Loaded! U-Net params: {n_params:,}\")\n",
                "    print(\"(Set USE_REAL_MODEL = True with GPU for real NSFW removal)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Generate Before Images\n",
                "\n",
                "Let's see what the model generates **before** unlearning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 7: Before-unlearning generation\n",
                "def generate_and_visualize(model, prompts, title, seed=42):\n",
                "    fig, axes = plt.subplots(1, len(prompts), figsize=(4 * len(prompts), 4))\n",
                "    if len(prompts) == 1:\n",
                "        axes = [axes]\n",
                "    latents = []\n",
                "    for ax, prompt in zip(axes, prompts):\n",
                "        if USE_REAL_MODEL and hasattr(model, 'generate_image'):\n",
                "            img = model.generate_image(\n",
                "                prompt, num_inference_steps=NUM_INFERENCE_STEPS,\n",
                "                generator=torch.Generator(device).manual_seed(seed),\n",
                "            )\n",
                "            ax.imshow(img)\n",
                "        else:\n",
                "            latent = model.generate_latent(prompt, seed=seed)\n",
                "            latents.append(latent)\n",
                "            img = latent[0].mean(dim=0).detach().cpu().numpy()\n",
                "            ax.imshow(img, cmap='RdBu_r', vmin=-2, vmax=2)\n",
                "        ax.set_title(prompt[:25] + ('...' if len(prompt) > 25 else ''), fontsize=9)\n",
                "        ax.axis('off')\n",
                "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
                "    plt.tight_layout()\n",
                "    plt.savefig('before_after_temp.png', dpi=100, bbox_inches='tight')\n",
                "    plt.show()\n",
                "    return latents\n",
                "\n",
                "print(\"BEFORE UNLEARNING\")\n",
                "print(\"=\" * 50)\n",
                "print(\"\\nNSFW prompts (will be disrupted after):\")\n",
                "before_nsfw = generate_and_visualize(model, TEST_PROMPTS[\"nsfw_test\"], \"BEFORE: NSFW Prompts\")\n",
                "print(\"\\nSafe prompts (should remain intact):\")\n",
                "before_safe = generate_and_visualize(model, TEST_PROMPTS[\"safe_test\"], \"BEFORE: Safe Prompts\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Measure Baseline Denoising Loss\n",
                "\n",
                "Lower loss = model can denoise this concept well = can generate it.  \n",
                "After unlearning, NSFW loss should **increase** (disrupted)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 8: Baseline denoising capability\n",
                "@torch.no_grad()\n",
                "def measure_denoising_loss(model, prompts, n_samples=5, seed=42):\n",
                "    \"\"\"Measure noise prediction MSE for given prompts.\"\"\"\n",
                "    torch.manual_seed(seed)\n",
                "    dev = next(model.unet.parameters()).device\n",
                "    total_loss = 0.0\n",
                "    for prompt in prompts:\n",
                "        tokens = model.tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
                "        text_emb = model.text_encoder(tokens.input_ids.to(dev))[0]\n",
                "        for _ in range(n_samples):\n",
                "            t = torch.randint(0, 1000, (1,), device=dev)\n",
                "            latent = torch.randn(1, 4, 64, 64, device=dev)\n",
                "            noise = torch.randn_like(latent)\n",
                "            noisy = model.scheduler.add_noise(latent, noise, t)\n",
                "            pred = model.unet(noisy, t, encoder_hidden_states=text_emb).sample\n",
                "            total_loss += F.mse_loss(pred, noise).item()\n",
                "    return total_loss / (len(prompts) * n_samples)\n",
                "\n",
                "nsfw_loss_before = measure_denoising_loss(model, NSFW_CONCEPTS[:5])\n",
                "safe_loss_before = measure_denoising_loss(model, SAFE_CONCEPTS[:5])\n",
                "\n",
                "print(f\"Baseline Denoising Loss (lower = can generate):\")\n",
                "print(f\"  NSFW: {nsfw_loss_before:.4f}\")\n",
                "print(f\"  Safe: {safe_loss_before:.4f}\")\n",
                "print(f\"\\nAfter unlearning: NSFW loss should INCREASE.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Run Concept Erasure\n",
                "\n",
                "Using Erasus's `ConceptErasureStrategy` (ESD):\n",
                "1. **Forget pass**: Gradient ascent on NSFW prompts (maximize noise prediction loss)\n",
                "2. **Retain pass** (every N steps): Gradient descent on safe prompts (preserve denoising)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 9: Dummy dataloaders (strategy interface requirement)\n",
                "forget_loader = DataLoader(\n",
                "    TensorDataset(torch.randn(16, 256), torch.zeros(16, dtype=torch.long)),\n",
                "    batch_size=8,\n",
                ")\n",
                "retain_loader = DataLoader(\n",
                "    TensorDataset(torch.randn(32, 256), torch.zeros(32, dtype=torch.long)),\n",
                "    batch_size=8,\n",
                ")\n",
                "print(\"Dataloaders ready.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 10: Run Concept Erasure!\n",
                "print(\"=\" * 60)\n",
                "print(\"  ERASING NSFW CONCEPTS\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"  Strategy:     concept_erasure (ESD)\")\n",
                "print(f\"  LR:           {LEARNING_RATE}\")\n",
                "print(f\"  Epochs:       {EPOCHS}\")\n",
                "print(f\"  Retain every: {RETAIN_EVERY} epochs\")\n",
                "print(f\"  NSFW prompts: {len(NSFW_CONCEPTS)}\")\n",
                "print(f\"  Safe prompts: {len(SAFE_CONCEPTS)}\")\n",
                "print()\n",
                "\n",
                "original_state = copy.deepcopy(model.unet.state_dict())\n",
                "\n",
                "strategy = ConceptErasureStrategy(\n",
                "    lr=LEARNING_RATE,\n",
                "    retain_every=RETAIN_EVERY,\n",
                ")\n",
                "\n",
                "t0 = time.time()\n",
                "model, forget_losses, retain_losses = strategy.unlearn(\n",
                "    model=model,\n",
                "    forget_loader=forget_loader,\n",
                "    retain_loader=retain_loader,\n",
                "    epochs=EPOCHS,\n",
                "    concept_prompts=NSFW_CONCEPTS,\n",
                "    retain_prompts=SAFE_CONCEPTS,\n",
                ")\n",
                "elapsed = time.time() - t0\n",
                "\n",
                "print(f\"\\nUnlearning complete in {elapsed:.1f}s\")\n",
                "if forget_losses:\n",
                "    print(f\"Forget loss: {forget_losses[0]:.4f} -> {forget_losses[-1]:.4f}\")\n",
                "if retain_losses:\n",
                "    print(f\"Retain loss: {retain_losses[0]:.4f} -> {retain_losses[-1]:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 11: Plot training curves\n",
                "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "if forget_losses:\n",
                "    ax1.plot(forget_losses, color='#e74c3c', linewidth=2, label='Forget Loss (NSFW)')\n",
                "    ax1.set_xlabel('Epoch')\n",
                "    ax1.set_ylabel('Loss')\n",
                "    ax1.set_title('Forget Loss (NSFW Concepts)', fontweight='bold')\n",
                "    ax1.legend()\n",
                "    ax1.grid(True, alpha=0.3)\n",
                "    ax1.annotate('Negative = gradient ASCENT\\n(maximizing loss = forgetting)',\n",
                "        xy=(0.5, 0.95), xycoords='axes fraction', ha='center', va='top', fontsize=9,\n",
                "        bbox=dict(boxstyle='round,pad=0.3', facecolor='#fce4ec', alpha=0.8))\n",
                "else:\n",
                "    ax1.text(0.5, 0.5, 'No forget losses', ha='center', va='center', transform=ax1.transAxes)\n",
                "\n",
                "if retain_losses:\n",
                "    ax2.plot(retain_losses, color='#2ecc71', linewidth=2, label='Retain Loss (Safe)')\n",
                "    ax2.set_xlabel('Epoch (retain steps)')\n",
                "    ax2.set_ylabel('Loss')\n",
                "    ax2.set_title('Retain Loss (Safe Concepts)', fontweight='bold')\n",
                "    ax2.legend()\n",
                "    ax2.grid(True, alpha=0.3)\n",
                "    ax2.annotate('Positive = gradient DESCENT\\n(minimizing loss = preserving)',\n",
                "        xy=(0.5, 0.95), xycoords='axes fraction', ha='center', va='top', fontsize=9,\n",
                "        bbox=dict(boxstyle='round,pad=0.3', facecolor='#e8f5e9', alpha=0.8))\n",
                "else:\n",
                "    ax2.text(0.5, 0.5, 'No retain losses', ha='center', va='center', transform=ax2.transAxes)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('training_curves.png', dpi=100, bbox_inches='tight')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Verify: After-Unlearning Generation\n",
                "\n",
                "- **NSFW prompts** should produce disrupted / incoherent output\n",
                "- **Safe prompts** should still produce reasonable output"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 12: After-unlearning generation\n",
                "print(\"AFTER UNLEARNING\")\n",
                "print(\"=\" * 50)\n",
                "print(\"\\nNSFW prompts (should be disrupted):\")\n",
                "after_nsfw = generate_and_visualize(model, TEST_PROMPTS[\"nsfw_test\"], \"AFTER: NSFW (Disrupted)\")\n",
                "print(\"\\nSafe prompts (should still work):\")\n",
                "after_safe = generate_and_visualize(model, TEST_PROMPTS[\"safe_test\"], \"AFTER: Safe (Preserved)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Quantitative Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 13: Before/after metrics\n",
                "nsfw_loss_after = measure_denoising_loss(model, NSFW_CONCEPTS[:5])\n",
                "safe_loss_after = measure_denoising_loss(model, SAFE_CONCEPTS[:5])\n",
                "\n",
                "print(\"=\" * 60)\n",
                "print(\"  QUANTITATIVE RESULTS\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"\\n  {'Metric':<25} {'Before':>10} {'After':>10} {'Change':>10}\")\n",
                "print(f\"  {'-' * 55}\")\n",
                "print(f\"  {'NSFW denoising loss':<25} {nsfw_loss_before:>10.4f} {nsfw_loss_after:>10.4f} {nsfw_loss_after - nsfw_loss_before:>+10.4f}\")\n",
                "print(f\"  {'Safe denoising loss':<25} {safe_loss_before:>10.4f} {safe_loss_after:>10.4f} {safe_loss_after - safe_loss_before:>+10.4f}\")\n",
                "\n",
                "# Weight change analysis\n",
                "current_state = model.unet.state_dict()\n",
                "weight_deltas = []\n",
                "for key in original_state:\n",
                "    delta = (current_state[key].float() - original_state[key].float()).norm().item()\n",
                "    weight_deltas.append((key, delta))\n",
                "weight_deltas.sort(key=lambda x: -x[1])\n",
                "total_delta = sum(d for _, d in weight_deltas)\n",
                "\n",
                "print(f\"\\n  Total weight change (L2): {total_delta:.4f}\")\n",
                "print(f\"  Most modified layers:\")\n",
                "for name, delta in weight_deltas[:5]:\n",
                "    print(f\"    {name}: {delta:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 14: Visualization dashboard\n",
                "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
                "\n",
                "# Bar chart: denoising loss\n",
                "categories = ['NSFW\\n(should increase)', 'Safe\\n(should stay low)']\n",
                "x = np.arange(len(categories))\n",
                "w = 0.35\n",
                "axes[0, 0].bar(x - w/2, [nsfw_loss_before, safe_loss_before], w, label='Before', color='#3498db', alpha=0.8)\n",
                "axes[0, 0].bar(x + w/2, [nsfw_loss_after, safe_loss_after], w, label='After', color='#e74c3c', alpha=0.8)\n",
                "axes[0, 0].set_ylabel('Denoising Loss')\n",
                "axes[0, 0].set_title('Before vs After', fontweight='bold')\n",
                "axes[0, 0].set_xticks(x)\n",
                "axes[0, 0].set_xticklabels(categories)\n",
                "axes[0, 0].legend()\n",
                "axes[0, 0].grid(True, alpha=0.3)\n",
                "\n",
                "# Weight change histogram\n",
                "deltas = [d for _, d in weight_deltas]\n",
                "axes[0, 1].hist(deltas, bins=15, color='#9b59b6', alpha=0.7, edgecolor='white')\n",
                "axes[0, 1].set_xlabel('Weight Change (L2)')\n",
                "axes[0, 1].set_ylabel('Layers')\n",
                "axes[0, 1].set_title('Weight Changes Distribution', fontweight='bold')\n",
                "axes[0, 1].grid(True, alpha=0.3)\n",
                "\n",
                "# Forget loss trajectory\n",
                "if forget_losses:\n",
                "    axes[1, 0].plot(forget_losses, color='#e74c3c', linewidth=2)\n",
                "    axes[1, 0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
                "    axes[1, 0].fill_between(range(len(forget_losses)), forget_losses, 0, alpha=0.1, color='#e74c3c')\n",
                "axes[1, 0].set_xlabel('Epoch')\n",
                "axes[1, 0].set_ylabel('Forget Loss')\n",
                "axes[1, 0].set_title('NSFW Forget Trajectory', fontweight='bold')\n",
                "axes[1, 0].grid(True, alpha=0.3)\n",
                "\n",
                "# Effectiveness scores\n",
                "forget_eff = (nsfw_loss_after - nsfw_loss_before) / max(nsfw_loss_before, 1e-8) * 100\n",
                "retain_pres = max(0, 100 - abs(safe_loss_after - safe_loss_before) / max(safe_loss_before, 1e-8) * 100)\n",
                "scores = [forget_eff, retain_pres]\n",
                "labels = ['Forget\\nEffectiveness', 'Retain\\nPreservation']\n",
                "colors = ['#e74c3c' if forget_eff > 0 else '#95a5a6', '#2ecc71']\n",
                "axes[1, 1].bar(labels, scores, color=colors, alpha=0.8, edgecolor='white', linewidth=2)\n",
                "axes[1, 1].set_ylabel('Score (%)')\n",
                "axes[1, 1].set_title('Effectiveness', fontweight='bold')\n",
                "axes[1, 1].grid(True, alpha=0.3)\n",
                "for i, v in enumerate(scores):\n",
                "    axes[1, 1].text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.savefig('evaluation_dashboard.png', dpi=100, bbox_inches='tight')\n",
                "plt.show()\n",
                "\n",
                "print(f\"Forget Effectiveness: {forget_eff:+.1f}%\")\n",
                "print(f\"Retain Preservation:  {retain_pres:.1f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Alternative: DiffusionUnlearner High-Level API\n",
                "\n",
                "Erasus provides `DiffusionUnlearner` for a streamlined workflow:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 15: DiffusionUnlearner API demo\n",
                "print(\"DiffusionUnlearner API\")\n",
                "print(\"=\" * 50)\n",
                "\n",
                "fresh_model = MiniStableDiffusion() if not USE_REAL_MODEL else model\n",
                "fresh_model.to(device)\n",
                "\n",
                "unlearner = DiffusionUnlearner(\n",
                "    model=fresh_model,\n",
                "    strategy=\"concept_erasure\",\n",
                "    selector=None,\n",
                "    device=device,\n",
                "    strategy_kwargs={\"lr\": LEARNING_RATE, \"retain_every\": RETAIN_EVERY},\n",
                ")\n",
                "\n",
                "result = unlearner.fit(\n",
                "    forget_data=forget_loader,\n",
                "    retain_data=retain_loader,\n",
                "    epochs=EPOCHS,\n",
                "    concept_prompts=NSFW_CONCEPTS,\n",
                "    retain_prompts=SAFE_CONCEPTS,\n",
                ")\n",
                "\n",
                "print(f\"  Elapsed: {result.elapsed_time:.1f}s\")\n",
                "print(f\"  Coreset size: {result.coreset_size}\")\n",
                "print(f\"  Compression: {result.compression_ratio:.3f}\")\n",
                "if result.forget_loss_history:\n",
                "    print(f\"  Forget loss: {result.forget_loss_history[0]:.4f} -> {result.forget_loss_history[-1]:.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. Compare Diffusion Strategies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 16: Strategy comparison\n",
                "strategies = [\n",
                "    (\"concept_erasure\", \"ESD concept removal\"),\n",
                "    (\"safe_latents\", \"Safe Latent Diffusion\"),\n",
                "    (\"gradient_ascent\", \"Vanilla gradient ascent\"),\n",
                "]\n",
                "\n",
                "print(\"Strategy Comparison\")\n",
                "print(\"=\" * 60)\n",
                "print(f\"{'Strategy':<25} {'Time':>8} {'Forget Loss':>12} {'Status':>8}\")\n",
                "print(\"-\" * 60)\n",
                "\n",
                "for sname, desc in strategies:\n",
                "    try:\n",
                "        m = MiniStableDiffusion() if not USE_REAL_MODEL else model\n",
                "        m.to(device)\n",
                "        u = DiffusionUnlearner(\n",
                "            model=m, strategy=sname, selector=None,\n",
                "            device=device, strategy_kwargs={\"lr\": LEARNING_RATE},\n",
                "        )\n",
                "        r = u.fit(forget_data=forget_loader, retain_data=retain_loader, epochs=min(EPOCHS, 20))\n",
                "        fl = r.forget_loss_history[-1] if r.forget_loss_history else 0\n",
                "        print(f\"{sname:<25} {r.elapsed_time:>7.1f}s {fl:>12.4f} {'OK':>8}\")\n",
                "    except Exception as e:\n",
                "        print(f\"{sname:<25} {'--':>8} {'--':>12} {'ERROR':>8}  ({str(e)[:40]})\")\n",
                "\n",
                "print(\"\\nconcept_erasure uses prompt-level erasure (best for diffusion).\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Summary & Next Steps\n",
                "\n",
                "### What We Achieved\n",
                "\n",
                "| Aspect | Result |\n",
                "|--------|--------|\n",
                "| **NSFW denoising** | Disrupted (loss increased) |\n",
                "| **Safe generation** | Preserved (loss stable) |\n",
                "| **Strategy** | ESD concept erasure |\n",
                "| **Weight changes** | Targeted to U-Net only |\n",
                "\n",
                "### Production Checklist\n",
                "\n",
                "1. **Set `USE_REAL_MODEL = True`** and load `stabilityai/stable-diffusion-2-1`\n",
                "2. **Increase epochs** to 200-500\n",
                "3. **Expand NSFW prompts** with comprehensive concept lists\n",
                "4. **Lower learning rate** to `1e-6`\n",
                "5. **Evaluate with FID** for generation quality\n",
                "6. **Test with adversarial prompts**\n",
                "7. **Save modified U-Net weights**\n",
                "\n",
                "### References\n",
                "\n",
                "- Erasus: https://github.com/OnePunchMonk/erasus\n",
                "- ESD: Gandikota et al., ICCV 2023\n",
                "- Safe Latent Diffusion: Schramowski et al., 2023"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Cell 17: Save results\n",
                "import json\n",
                "from pathlib import Path\n",
                "\n",
                "results = {\n",
                "    \"mode\": \"production\" if USE_REAL_MODEL else \"demo\",\n",
                "    \"model\": REAL_MODEL_ID if USE_REAL_MODEL else \"MiniStableDiffusion\",\n",
                "    \"strategy\": \"concept_erasure\",\n",
                "    \"epochs\": EPOCHS,\n",
                "    \"lr\": LEARNING_RATE,\n",
                "    \"nsfw_loss_before\": nsfw_loss_before,\n",
                "    \"nsfw_loss_after\": nsfw_loss_after,\n",
                "    \"safe_loss_before\": safe_loss_before,\n",
                "    \"safe_loss_after\": safe_loss_after,\n",
                "    \"forget_effectiveness_pct\": forget_eff,\n",
                "    \"retain_preservation_pct\": retain_pres,\n",
                "    \"total_weight_delta\": total_delta,\n",
                "    \"elapsed_seconds\": elapsed,\n",
                "}\n",
                "\n",
                "out = Path(\"nsfw_removal_results.json\")\n",
                "with open(out, \"w\") as f:\n",
                "    json.dump(results, f, indent=2)\n",
                "\n",
                "print(f\"Results saved to {out}\")\n",
                "print(\"Done! NSFW concept removal complete.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.13.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}